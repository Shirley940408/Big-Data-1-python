1. What happened when you inserted another row with the same primary key as an existing row?
it overwrites the existing row with the new values for the same primary key.
Any unspecified columns keep their previous values.

2.What happened when you query a keyspace with replication factor 1 and one node down? How did it behave with replication factor 2 and a node down?

cqlsh:sya236> CONSISTENCY ONE;
Consistency level set to ONE.
cqlsh:sya236> SELECT * FROM t WHERE id IN (1,2,3,10,20,30,100,200,300);

 id  | data
-----+------
   1 |    a
   2 |    b
   3 |    c
  10 |    x
  20 |    y
  30 |    z
 100 |    m
 200 |    n
 300 |    p

(9 rows)
cqlsh:sya236> SELECT * FROM t WHERE id IN (1,2,3,10,20,30,100,200,300);
NoHostAvailable: ('Unable to complete the operation against any hosts', {<Host: 10.17.203.211:9042 datacenter1>: Unavailable('Error from server: code=1000 [Unavailable exception] message="Cannot achieve consistency level ONE" info={\'consistency\': \'ONE\', \'required_replicas\': 1, \'alive_replicas\': 0}')})
cqlsh:sya236> SELECT * FROM test;
NoHostAvailable: ('Unable to complete the operation against any hosts', {<Host: 10.17.203.211:9042 datacenter1>: Unavailable('Error from server: code=1000 [Unavailable exception] message="Cannot achieve consistency level ALL" info={\'consistency\': \'ALL\', \'required_replicas\': 2, \'alive_replicas\': 1}')})
cqlsh:sya236> SELECT * FROM test WHERE id=1;
NoHostAvailable: ('Unable to complete the operation against any hosts', {<Host: 10.17.203.211:9042 datacenter1>: Unavailable('Error from server: code=1000 [Unavailable exception] message="Cannot achieve consistency level ALL" info={\'consistency\': \'ALL\', \'required_replicas\': 2, \'alive_replicas\': 1}')})
cqlsh:sya236> CONSISTENCY ONE;
Consistency level set to ONE.
cqlsh:sya236> SELECT * FROM test WHERE id=1;

 id | data
----+---------
  1 | initial

(1 rows)

cqlsh:sya236> SELECT * FROM test
          ... ;

 id | data
----+-------------
  5 |        cinq
  1 |     initial
  8 |   octagonal
  2 |      double
  4 |      square
  7 |    sevenish
  6 | hexadecimal
  9 |        neun
  3 |    tertiary

When the replication factor was 1:
With CONSISTENCY ONE, both inserts and queries failed when the node responsible for the partition was down.
Because there was only a single replica, and that replica was unavailable, Cassandra could not satisfy the required consistency level.
With CONSISTENCY ALL, behavior was the same: since there was only one replica, it also failed when that node was down.
In this case, ONE and ALL are effectively equivalent, because both require the only replica to be alive.
When the replication factor was 2:
With CONSISTENCY ONE, inserts and queries succeeded even when one node was down,
because Cassandra only needed one replica to respond, and the other node was still available.
With CONSISTENCY ALL, both operations failed when one node was down,
because Cassandra required both replicas to acknowledge the operation, and one was unavailable.
In summary, the outcome depended on the chosen consistency level.
CONSISTENCY ONE allows operations to succeed as long as at least one replica is alive,
while CONSISTENCY ALL requires all replicas to be reachable, failing if any node is down.

3. How did the consistency level affect the results with the node up/down?
The results depended on the chosen consistency level.
With CONSISTENCY ONE, both read and write operations succeeded as long as at least one replica was up.
When a node was down, Cassandra could still complete the operation using the remaining replica(s).
With CONSISTENCY ALL, operations failed whenever any replica was down,
since Cassandra required every replica to acknowledge the operation for it to be considered successful.
In summary, lower consistency levels like ONE favor availability under node failures,
while higher levels like ALL favor consistency but reduce fault tolerance.

4. Which of the WHERE id=? values returned successfully with CONSISTENCY ALL when one of the nodes was down? Why do you think some could be returned but not others?
cqlsh:sya236>  SELECT * FROM test WHERE id=2
          ... ;

 id | data
----+--------
  2 | double

(1 rows)

Tracing session: a52576f0-b620-11f0-94b7-f76e08cd7858

 activity                                                                                        | timestamp                  | source        | source_elapsed | client
-------------------------------------------------------------------------------------------------+----------------------------+---------------+----------------+-------------
                                                                              Execute CQL3 query | 2025-10-30 23:12:57.439000 | 10.17.203.211 |              0 | 10.17.203.1
                         Parsing SELECT * FROM test WHERE id=2 \n; [Native-Transport-Requests-1] | 2025-10-30 23:12:57.439001 | 10.17.203.211 |            251 | 10.17.203.1
                                               Preparing statement [Native-Transport-Requests-1] | 2025-10-30 23:12:57.439002 | 10.17.203.211 |            409 | 10.17.203.1
                           reading digest from /10.17.203.212:7000 [Native-Transport-Requests-1] | 2025-10-30 23:12:57.440000 | 10.17.203.211 |            742 | 10.17.203.1
                    READ_REQ message received from /10.17.203.211:7000 [Messaging-EventLoop-3-2] | 2025-10-30 23:12:57.440000 | 10.17.203.212 |             28 | 10.17.203.1
                                          Executing single-partition query on test [ReadStage-2] | 2025-10-30 23:12:57.440001 | 10.17.203.211 |            974 | 10.17.203.1
 Sending READ_REQ message to /10.17.203.212:7000 message size 83 bytes [Messaging-EventLoop-3-1] | 2025-10-30 23:12:57.440002 | 10.17.203.211 |           1009 | 10.17.203.1
                                                      Acquiring sstable references [ReadStage-2] | 2025-10-30 23:12:57.440003 | 10.17.203.211 |           1081 | 10.17.203.1
                                                         Merging memtable contents [ReadStage-2] | 2025-10-30 23:12:57.440004 | 10.17.203.211 |           1123 | 10.17.203.1
                                                       Key cache hit for sstable 5 [ReadStage-2] | 2025-10-30 23:12:57.440005 | 10.17.203.211 |           1226 | 10.17.203.1
                                            Read 1 live rows and 0 tombstone cells [ReadStage-2] | 2025-10-30 23:12:57.440006 | 10.17.203.211 |           1460 | 10.17.203.1
                                          Executing single-partition query on test [ReadStage-1] | 2025-10-30 23:12:57.441000 | 10.17.203.212 |            658 | 10.17.203.1
                                                      Acquiring sstable references [ReadStage-1] | 2025-10-30 23:12:57.441001 | 10.17.203.212 |            809 | 10.17.203.1
                                                         Merging memtable contents [ReadStage-1] | 2025-10-30 23:12:57.441002 | 10.17.203.212 |            916 | 10.17.203.1
                                                       Key cache hit for sstable 5 [ReadStage-1] | 2025-10-30 23:12:57.441003 | 10.17.203.212 |           1029 | 10.17.203.1
                                            Read 1 live rows and 0 tombstone cells [ReadStage-1] | 2025-10-30 23:12:57.442000 | 10.17.203.212 |           1603 | 10.17.203.1
                                         Enqueuing response to /10.17.203.211:7000 [ReadStage-1] | 2025-10-30 23:12:57.442001 | 10.17.203.212 |           1696 | 10.17.203.1
 Sending READ_RSP message to /10.17.203.211:7000 message size 52 bytes [Messaging-EventLoop-3-2] | 2025-10-30 23:12:57.443000 | 10.17.203.212 |           2309 | 10.17.203.1
                    READ_RSP message received from /10.17.203.212:7000 [Messaging-EventLoop-3-2] | 2025-10-30 23:12:57.444000 | 10.17.203.211 |           4567 | 10.17.203.1
                           Processing response from /10.17.203.212:7000 [RequestResponseStage-3] | 2025-10-30 23:12:57.444001 | 10.17.203.211 |           4728 | 10.17.203.1
                                                                                Request complete | 2025-10-30 23:12:57.444402 | 10.17.203.211 |           5402 | 10.17.203.1


cqlsh:sya236>  SELECT * FROM test WHERE id=3;
NoHostAvailable: ('Unable to complete the operation against any hosts', {<Host: 10.17.203.211:9042 datacenter1>: Unavailable('Error from server: code=1000 [Unavailable exception] message="Cannot achieve consistency level ALL" info={\'consistency\': \'ALL\', \'required_replicas\': 2, \'alive_replicas\': 1}')})

Because the cluster has three nodes, any partition whose replicas are stored only on the two healthy nodes (211 and 212) can still be read successfully under CONSISTENCY ALL.
for id = 2 we have this:
     reading digest from /10.17.203.212:7000 [Native-Transport-Requests-1] | 2025-10-30 23:12:57.440000 | 10.17.203.211 |            742 | 10.17.203.1
     READ_REQ message received from /10.17.203.211:7000 [Messaging-EventLoop-3-2] | 2025-10-30 23:12:57.440000 | 10.17.203.212 |             28 | 10.17.203.1
Thus the only two nodes involved are /10.17.203.212 and /10.17.203.211, no 213 involved. So this one works.

5. What was the CREATE TABLE statement you used for the nasalogs table? What was the primary key you choose, and why?
CREATE TABLE nasalogs (
  host text,
  datetime timestamp,
  path text,
  bytes int,
  req_id timeuuid,
  PRIMARY KEY ((host), datetime, req_id)
) WITH CLUSTERING ORDER BY (datetime ASC);

I have chosen host as primary partition key for making the same host together on the same node. In this way we could easily aggregrate by host for later analysis.
I have also chosen datatime as cluster key, for it would be easy to sort base on time sequence.
And the same host could also get http response at the same minute, thus we need another unique id to make the difference, which is req_id (a unique timeuuid).
In summary, this schema keeps all log entries for the same host on one node, sorted by request time, while preventing overwrites caused by identical timestamps.

6. What was the CQL query you used (or tried) to get the total number of bytes?
SELECT sum(bytes) From nasalogs
